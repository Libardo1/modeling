{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(\n",
    "            itertools.combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import modeling.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For scikit learn metrics.\n",
    "precision_recall_average = 'macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best so far, but imbalanced.\n",
    "model_dir = 'models/keras/preposition/convnet/20a7a6b088ee11e5b2b374d435ed6f3a/'\n",
    "\n",
    "# Balanced.\n",
    "# model_dir = 'models/keras/preposition/convnet/balanced/'\n",
    "\n",
    "# Load the test set for evaluation.\n",
    "data_file = 'data/preposition/prepositions-all-new-test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights (build_model)\n",
      "Loading weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "model, model_cfg = modeling.utils.load_model(model_dir, load_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(999552, 5), (999552, 52)]\n"
     ]
    }
   ],
   "source": [
    "model_data = modeling.utils.load_all_model_data(data_file, model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load target data or metadata (e.g. mapping between numeric target variable and preposition).\n",
    "target_data_file = 'data/preposition/prepositions-all-new-target-data.json'\n",
    "target_data = json.load(open(target_data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_n_unknown_words():\n",
    "    n_unknown_words = np.zeros_like(model_data.len)\n",
    "    for i in np.arange(0, len(model_data.len)):\n",
    "        n_unknown_words[i] = len(np.where(model_data.data[i, 0:model_data.len[i]] == 0)[0])\n",
    "    return n_unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity analysis of effect of position of unknown words in window around preposition\n",
    "=======\n",
    "1. Take all examples in which the window around the preposition contains no unknown words.\n",
    "2. For each set in the powerset of positions in the window (excluding the center, where the preposition occurs):\n",
    "  1. Set the words in that position to be unknown (i.e. assign 0 to that position) for all examples.\n",
    "  2. Run the examples through the model.\n",
    "3. Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sensitivity_analysis(n=50000):\n",
    "    n_unknown_words = compute_n_unknown_words()\n",
    "\n",
    "    print('# of examples ' + str(len(model_data.data)))\n",
    "    print('# of examples with no unknown words ' + str((n_unknown_words==0).sum()))\n",
    "    \n",
    "    error_detection_targets = np.ones_like(model_data.current_word_code)\n",
    "    evens = np.arange(0, len(model_data.target), 2)\n",
    "    error_detection_targets[evens] = 0\n",
    "\n",
    "    no_unknown_words_data = model_data.data[n_unknown_words == 0]\n",
    "    no_unknown_words_correction_targets = model_data.target[n_unknown_words == 0]\n",
    "    no_unknown_words_detection_targets = error_detection_targets[n_unknown_words == 0]\n",
    "\n",
    "    window_size = 5\n",
    "    center = 2\n",
    "\n",
    "    assert len(np.where(model_data.data[:, center] == 0)[0]) == 0\n",
    "\n",
    "    indices_in_window = [center-2, center-1, center+1, center+2]\n",
    "\n",
    "    masks = [mask for mask in powerset(indices_in_window)]\n",
    "\n",
    "    correction_results = {}\n",
    "    \n",
    "    results_df = None\n",
    "\n",
    "    for mask in masks:\n",
    "        data = no_unknown_words_data.copy()[0:n]\n",
    "        mask = np.array(mask, dtype=int)\n",
    "\n",
    "        data[:, mask] = 0\n",
    "\n",
    "        for i in np.arange(len(data)):\n",
    "            data[i, mask + model_data.position[i] + 3] = 0\n",
    "\n",
    "        no_unknown_words_correction_preds = model.predict_classes(data, verbose=0)\n",
    "\n",
    "        unknowns_str = ['_'] * (len(indices_in_window) + 1)\n",
    "        for x in mask:\n",
    "            unknowns_str[x] = \"?\"\n",
    "        unknowns_str[center] = \"P\"\n",
    "\n",
    "        # Error correction\n",
    "        p, r, f, _ = precision_recall_fscore_support(\n",
    "                no_unknown_words_correction_targets[0:n],\n",
    "                no_unknown_words_correction_preds,\n",
    "                average=precision_recall_average)\n",
    "        \n",
    "        row = pd.DataFrame({\n",
    "                \"pos-2\": [unknowns_str[0]],\n",
    "                \"pos-1\": [unknowns_str[1]],\n",
    "                \"pos-0\": [unknowns_str[2]],\n",
    "                \"pos+1\": [unknowns_str[3]],\n",
    "                \"pos+2\": [unknowns_str[4]],\n",
    "                \"precision\": [p],\n",
    "                \"recall\": [r],\n",
    "                \"f1\": [f],\n",
    "                \"n\": [n]\n",
    "                    })\n",
    "        if results_df is None:\n",
    "            results_df = row\n",
    "        else:\n",
    "            results_df = pd.concat([results_df, row])\n",
    "\n",
    "    results_df = results_df[[\"pos-2\", \"pos-1\", \"pos-0\", \"pos+1\", \"pos+2\", \"precision\", \"recall\", \"f1\", \"n\"]]\n",
    "    print(results_df.to_latex(index=False, float_format=lambda f: '%.02f' % f))\n",
    "      \n",
    "sensitivity_analysis(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
